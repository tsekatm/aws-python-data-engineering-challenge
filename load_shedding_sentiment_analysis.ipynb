{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86da3d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SentimentAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.vader = SentimentIntensityAnalyzer()\n",
    "        try:\n",
    "            self.transformer_sentiment = pipeline(\n",
    "                'sentiment-analysis',\n",
    "                model='cardiffnlp/twitter-roberta-base-sentiment-latest'\n",
    "            )\n",
    "            self.has_transformer = True\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not load transformer model: {e}\")\n",
    "            self.has_transformer = False\n",
    "\n",
    "    def analyze_vader_sentiment(self, text):\n",
    "        if pd.isna(text) or text == '':\n",
    "            return {'compound': 0, 'pos': 0, 'neu': 1, 'neg': 0}\n",
    "        return self.vader.polarity_scores(str(text))\n",
    "\n",
    "    def analyze_textblob_sentiment(self, text):\n",
    "        if pd.isna(text) or text == '':\n",
    "            return 0.0\n",
    "        return TextBlob(str(text)).sentiment.polarity\n",
    "\n",
    "    def analyze_transformer_sentiment(self, text):\n",
    "        if not self.has_transformer or pd.isna(text) or text == '':\n",
    "            return {'label': 'NEUTRAL', 'score': 0.0}\n",
    "        try:\n",
    "            result = self.transformer_sentiment(text[:512])[0]\n",
    "            return {'label': result['label'], 'score': result['score']}\n",
    "        except:\n",
    "            return {'label': 'ERROR', 'score': 0.0}\n",
    "\n",
    "# Initialize analyzer\n",
    "sentiment = SentimentAnalyzer()\n",
    "\n",
    "# Apply to both datasets\n",
    "if not twitter_df.empty:\n",
    "    print(\"Analyzing Twitter sentiment...\")\n",
    "    twitter_df['vader'] = twitter_df['cleaned_text'].apply(sentiment.analyze_vader_sentiment)\n",
    "    twitter_df['vader_compound'] = twitter_df['vader'].apply(lambda x: x['compound'])\n",
    "    twitter_df['textblob'] = twitter_df['cleaned_text'].apply(sentiment.analyze_textblob_sentiment)\n",
    "\n",
    "if not reddit_df.empty:\n",
    "    print(\"Analyzing Reddit sentiment...\")\n",
    "    reddit_df['vader'] = reddit_df['cleaned_text'].apply(sentiment.analyze_vader_sentiment)\n",
    "    reddit_df['vader_compound'] = reddit_df['vader'].apply(lambda x: x['compound'])\n",
    "    reddit_df['textblob'] = reddit_df['cleaned_text'].apply(sentiment.analyze_textblob_sentiment)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f97c32",
   "metadata": {},
   "source": [
    "## 6. Visualization & Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da0171c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Combine Twitter and Reddit data\n",
    "twitter_df['platform'] = 'Twitter'\n",
    "reddit_df['platform'] = 'Reddit'\n",
    "combined_df = pd.concat([\n",
    "    twitter_df[['created_at', 'cleaned_text', 'vader_compound', 'textblob', 'platform']],\n",
    "    reddit_df[['created_at', 'cleaned_text', 'vader_compound', 'textblob', 'platform']]\n",
    "], ignore_index=True)\n",
    "\n",
    "# Convert created_at to datetime if not already\n",
    "combined_df['created_at'] = pd.to_datetime(combined_df['created_at'])\n",
    "\n",
    "# Plot sentiment over time\n",
    "plt.figure(figsize=(12, 6))\n",
    "combined_df.set_index('created_at').resample('D')['vader_compound'].mean().plot(label='VADER Sentiment')\n",
    "combined_df.set_index('created_at').resample('D')['textblob'].mean().plot(label='TextBlob Sentiment')\n",
    "plt.title('Daily Average Sentiment Over Time')\n",
    "plt.ylabel('Sentiment Score')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec7ba49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Correlate with economic indicators\n",
    "def plot_correlation_with_sentiment(sentiment_series, economic_df, title):\n",
    "    combined = pd.DataFrame({\n",
    "        'sentiment': sentiment_series.resample('D').mean()\n",
    "    })\n",
    "    combined = combined.join(economic_df['Close'].resample('D').mean(), how='inner')\n",
    "    combined.columns = ['Sentiment', 'Economic Indicator']\n",
    "    combined.dropna(inplace=True)\n",
    "    corr = combined.corr().iloc[0,1]\n",
    "    \n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "    fig.add_trace(go.Scatter(x=combined.index, y=combined['Sentiment'], name='Sentiment'), secondary_y=False)\n",
    "    fig.add_trace(go.Scatter(x=combined.index, y=combined['Economic Indicator'], name='Economic'), secondary_y=True)\n",
    "    fig.update_layout(title=f'{title} (Corr: {corr:.2f})', xaxis_title='Date')\n",
    "    fig.show()\n",
    "\n",
    "# Convert to datetime index\n",
    "combined_df.set_index('created_at', inplace=True)\n",
    "\n",
    "# Plot correlations\n",
    "plot_correlation_with_sentiment(combined_df['vader_compound'], economic_data['USDZAR'], 'Sentiment vs USD/ZAR')\n",
    "plot_correlation_with_sentiment(combined_df['vader_compound'], economic_data['JSE'], 'Sentiment vs JSE Index')\n",
    "plot_correlation_with_sentiment(combined_df['vader_compound'], economic_data['EZA'], 'Sentiment vs EZA ETF')\n",
    "        "
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
